{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896a6987",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-30T09:32:33.889642Z",
     "iopub.status.busy": "2025-07-30T09:32:33.888971Z",
     "iopub.status.idle": "2025-07-30T09:32:35.784113Z",
     "shell.execute_reply": "2025-07-30T09:32:35.782981Z"
    },
    "papermill": {
     "duration": 1.903001,
     "end_time": "2025-07-30T09:32:35.785785",
     "exception": false,
     "start_time": "2025-07-30T09:32:33.882784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/neurips-open-polymer-prediction-2025/sample_submission.csv\n",
      "/kaggle/input/neurips-open-polymer-prediction-2025/train.csv\n",
      "/kaggle/input/neurips-open-polymer-prediction-2025/test.csv\n",
      "/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset2.csv\n",
      "/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset4.csv\n",
      "/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset1.csv\n",
      "/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset3.csv\n",
      "/kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab26b37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T09:32:35.795796Z",
     "iopub.status.busy": "2025-07-30T09:32:35.794797Z",
     "iopub.status.idle": "2025-07-30T09:32:42.720844Z",
     "shell.execute_reply": "2025-07-30T09:32:42.719588Z"
    },
    "papermill": {
     "duration": 6.932714,
     "end_time": "2025-07-30T09:32:42.722648",
     "exception": false,
     "start_time": "2025-07-30T09:32:35.789934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit==2025.3.3) (1.26.4)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit==2025.3.3) (11.2.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit==2025.3.3) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit==2025.3.3) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit==2025.3.3) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit==2025.3.3) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit==2025.3.3) (2024.2.0)\r\n",
      "Installing collected packages: rdkit\r\n",
      "Successfully installed rdkit-2025.3.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432c5b3e",
   "metadata": {
    "papermill": {
     "duration": 0.003404,
     "end_time": "2025-07-30T09:32:42.729993",
     "exception": false,
     "start_time": "2025-07-30T09:32:42.726589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading and Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "720b7b28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T09:32:42.739380Z",
     "iopub.status.busy": "2025-07-30T09:32:42.738622Z",
     "iopub.status.idle": "2025-07-30T09:32:49.643819Z",
     "shell.execute_reply": "2025-07-30T09:32:49.642768Z"
    },
    "papermill": {
     "duration": 6.911642,
     "end_time": "2025-07-30T09:32:49.645339",
     "exception": false,
     "start_time": "2025-07-30T09:32:42.733697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded /kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset1.csv (874 entries for Tc)\n",
      "‚úÖ Loaded /kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset3.csv (46 entries for Tg)\n",
      "‚úÖ Loaded /kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset4.csv (862 entries for FFV)\n",
      "\n",
      "üìä Final Summary:\n",
      "Train: 7973 | Extended: 8972\n",
      "‚Ä¢ Tg      : 557 total (+46 from supplements)\n",
      "‚Ä¢ FFV     : 7892 total (+862 from supplements)\n",
      "‚Ä¢ Tc      : 866 total (+129 from supplements)\n",
      "‚Ä¢ Density : 613 total (+0 from supplements)\n",
      "‚Ä¢ Rg      : 614 total (+0 from supplements)\n",
      "\n",
      "‚úÖ Data loading and preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "\n",
    "# === Config ===\n",
    "BASE_PATH = '/kaggle/input/neurips-open-polymer-prediction-2025/'\n",
    "TARGETS = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "BAD_PATTERNS = ['[R]', '[R1]', '[R2]', '[R3]', '[R4]', '[R5]',\n",
    "                \"[R']\", '[R\"]', 'R1', 'R2', 'R3', 'R4', 'R5',\n",
    "                '([R])', '([R1])', '([R2])']\n",
    "\n",
    "# === SMILES Cleaner ===\n",
    "def clean_and_validate_smiles(smiles):\n",
    "    if not isinstance(smiles, str) or not smiles:\n",
    "        return None\n",
    "    for pattern in BAD_PATTERNS:\n",
    "        if pattern in smiles:\n",
    "            return None\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol:\n",
    "            return Chem.MolToSmiles(mol, canonical=True)\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "# === Load Train/Test ===\n",
    "train = pd.read_csv(BASE_PATH + 'train.csv')\n",
    "test = pd.read_csv(BASE_PATH + 'test.csv')\n",
    "\n",
    "train['SMILES'] = train['SMILES'].apply(clean_and_validate_smiles)\n",
    "test['SMILES'] = test['SMILES'].apply(clean_and_validate_smiles)\n",
    "\n",
    "train.dropna(subset=['SMILES'], inplace=True)\n",
    "test.dropna(subset=['SMILES'], inplace=True)\n",
    "\n",
    "# === Load External Datasets (excluding dataset2) ===\n",
    "external_datasets = []\n",
    "\n",
    "def load_external(path, target, rename_map=None):\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        if rename_map:\n",
    "            df = df.rename(columns=rename_map)\n",
    "        if 'SMILES' in df.columns and target in df.columns:\n",
    "            df = df[['SMILES', target]].dropna()\n",
    "            external_datasets.append((target, df))\n",
    "            print(f\"‚úÖ Loaded {path} ({len(df)} entries for {target})\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Skipped {path}: required columns missing\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to load {path}: {e}\")\n",
    "\n",
    "load_external(BASE_PATH + 'train_supplement/dataset1.csv', 'Tc', rename_map={'TC_mean': 'Tc'})\n",
    "load_external(BASE_PATH + 'train_supplement/dataset3.csv', 'Tg')\n",
    "load_external(BASE_PATH + 'train_supplement/dataset4.csv', 'FFV')\n",
    "\n",
    "# === Merge External Data ===\n",
    "def merge_external(train_df, ext_df, target):\n",
    "    ext_df['SMILES'] = ext_df['SMILES'].apply(clean_and_validate_smiles)\n",
    "    ext_df = ext_df.dropna(subset=['SMILES', target])\n",
    "    ext_df = ext_df.groupby('SMILES', as_index=False)[target].mean()\n",
    "\n",
    "    # Fill missing target values in existing rows\n",
    "    existing_smiles = set(train_df['SMILES'])\n",
    "    to_fill = ext_df[ext_df['SMILES'].isin(existing_smiles)]\n",
    "    for _, row in to_fill.iterrows():\n",
    "        mask = (train_df['SMILES'] == row['SMILES']) & (train_df[target].isna())\n",
    "        train_df.loc[mask, target] = row[target]\n",
    "\n",
    "    # Add new rows\n",
    "    new_smiles = set(ext_df['SMILES']) - existing_smiles\n",
    "    new_rows = ext_df[ext_df['SMILES'].isin(new_smiles)].copy()\n",
    "    for col in TARGETS:\n",
    "        if col not in new_rows.columns:\n",
    "            new_rows[col] = np.nan\n",
    "    return pd.concat([train_df, new_rows[['SMILES'] + TARGETS]], ignore_index=True)\n",
    "\n",
    "# === Apply Merges ===\n",
    "train_extended = train[['SMILES'] + TARGETS].copy()\n",
    "for target, ext in external_datasets:\n",
    "    train_extended = merge_external(train_extended, ext, target)\n",
    "\n",
    "# === Final Clean-Up ===\n",
    "train_extended = train_extended.replace([np.inf, -np.inf], np.nan)\n",
    "train_extended = train_extended.dropna(subset=TARGETS, how='all')\n",
    "train_extended = train_extended.drop_duplicates(subset=['SMILES']).reset_index(drop=True)\n",
    "\n",
    "# === Summary ===\n",
    "print(\"\\nüìä Final Summary:\")\n",
    "print(f\"Train: {len(train)} | Extended: {len(train_extended)}\")\n",
    "for t in TARGETS:\n",
    "    base = train[t].notna().sum()\n",
    "    ext = train_extended[t].notna().sum()\n",
    "    print(f\"‚Ä¢ {t:<8}: {ext} total ({ext - base:+} from supplements)\")\n",
    "\n",
    "print(\"\\n‚úÖ Data loading and preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef462d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T09:32:49.654542Z",
     "iopub.status.busy": "2025-07-30T09:32:49.654179Z",
     "iopub.status.idle": "2025-07-30T09:32:54.983780Z",
     "shell.execute_reply": "2025-07-30T09:32:54.982869Z"
    },
    "papermill": {
     "duration": 5.336095,
     "end_time": "2025-07-30T09:32:54.985424",
     "exception": false,
     "start_time": "2025-07-30T09:32:49.649329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Tg</th>\n",
       "      <th>FFV</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Density</th>\n",
       "      <th>Rg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*CC(*)c1ccccc1C(=O)OCCCCCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.374645</td>\n",
       "      <td>0.205667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*Nc1ccc([C@H](CCC)c2ccc(C3(c4ccc([C@@H](CCC)c5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.370410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*Oc1ccc(S(=O)(=O)c2ccc(Oc3ccc(C4(c5ccc(Oc6ccc(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*Nc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(N*)...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.387324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*Oc1ccc(OC(=O)c2cc(OCCCCCCCCCOCC3CCCN3c3ccc([N...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8967</th>\n",
       "      <td>*c1cccc(OCCCCCCOc2cccc(N3C(=O)c4ccc(-c5cccc6c5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.349095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8968</th>\n",
       "      <td>*c1cccc(OCCCCCOc2cccc(N3C(=O)c4ccc(-c5cccc6c5C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.350892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8969</th>\n",
       "      <td>*c1cccc(OCCCCOc2cccc(N3C(=O)c4ccc(-c5cccc6c5C(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.345386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8970</th>\n",
       "      <td>*c1cccc(Oc2cccc(Oc3cccc(N4C(=O)c5ccc(Oc6ccc(Sc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.362224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8971</th>\n",
       "      <td>*c1cccc(P(C)(=O)c2cccc(N3C(=O)c4ccc(Oc5ccc(C(C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.369574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8972 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SMILES  Tg       FFV  \\\n",
       "0                            *CC(*)c1ccccc1C(=O)OCCCCCC NaN  0.374645   \n",
       "1     *Nc1ccc([C@H](CCC)c2ccc(C3(c4ccc([C@@H](CCC)c5... NaN  0.370410   \n",
       "2     *Oc1ccc(S(=O)(=O)c2ccc(Oc3ccc(C4(c5ccc(Oc6ccc(... NaN  0.378860   \n",
       "3     *Nc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(N*)... NaN  0.387324   \n",
       "4     *Oc1ccc(OC(=O)c2cc(OCCCCCCCCCOCC3CCCN3c3ccc([N... NaN  0.355470   \n",
       "...                                                 ...  ..       ...   \n",
       "8967  *c1cccc(OCCCCCCOc2cccc(N3C(=O)c4ccc(-c5cccc6c5... NaN  0.349095   \n",
       "8968  *c1cccc(OCCCCCOc2cccc(N3C(=O)c4ccc(-c5cccc6c5C... NaN  0.350892   \n",
       "8969  *c1cccc(OCCCCOc2cccc(N3C(=O)c4ccc(-c5cccc6c5C(... NaN  0.345386   \n",
       "8970  *c1cccc(Oc2cccc(Oc3cccc(N4C(=O)c5ccc(Oc6ccc(Sc... NaN  0.362224   \n",
       "8971  *c1cccc(P(C)(=O)c2cccc(N3C(=O)c4ccc(Oc5ccc(C(C... NaN  0.369574   \n",
       "\n",
       "            Tc  Density  Rg  \n",
       "0     0.205667      NaN NaN  \n",
       "1          NaN      NaN NaN  \n",
       "2          NaN      NaN NaN  \n",
       "3          NaN      NaN NaN  \n",
       "4          NaN      NaN NaN  \n",
       "...        ...      ...  ..  \n",
       "8967       NaN      NaN NaN  \n",
       "8968       NaN      NaN NaN  \n",
       "8969       NaN      NaN NaN  \n",
       "8970       NaN      NaN NaN  \n",
       "8971       NaN      NaN NaN  \n",
       "\n",
       "[8972 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_list = train_extended['SMILES'].tolist()\n",
    "# Clean SMILES column robustly\n",
    "train_extended['SMILES'] = train_extended['SMILES'].apply(clean_and_validate_smiles)\n",
    "train_extended.shape\n",
    "train_extended"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47734b4",
   "metadata": {
    "papermill": {
     "duration": 0.003842,
     "end_time": "2025-07-30T09:32:54.993691",
     "exception": false,
     "start_time": "2025-07-30T09:32:54.989849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "286bbb99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T09:32:55.003160Z",
     "iopub.status.busy": "2025-07-30T09:32:55.002847Z",
     "iopub.status.idle": "2025-07-30T09:32:56.003871Z",
     "shell.execute_reply": "2025-07-30T09:32:56.002963Z"
    },
    "papermill": {
     "duration": 1.007889,
     "end_time": "2025-07-30T09:32:56.005609",
     "exception": false,
     "start_time": "2025-07-30T09:32:54.997720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Canonicalize SMILES ===\n",
    "def canonicalize_smiles(smiles_list):\n",
    "    canonical = []\n",
    "    for smi in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        if mol:\n",
    "            canonical.append(Chem.MolToSmiles(mol, canonical=True))\n",
    "        else:\n",
    "            canonical.append(None)\n",
    "    return canonical\n",
    "\n",
    "# === All RDKit Descriptors ===\n",
    "def compute_rdkit_descriptors(mol):\n",
    "    descs = {}\n",
    "    for name, func in Descriptors.descList:\n",
    "        try:\n",
    "            descs[name] = func(mol)\n",
    "        except:\n",
    "            descs[name] = np.nan\n",
    "    return descs\n",
    "\n",
    "# === Graph Features ===\n",
    "def compute_graph_descriptors(mol):\n",
    "    descriptors = {}\n",
    "    g = nx.Graph()\n",
    "    g.add_edges_from([(b.GetBeginAtomIdx(), b.GetEndAtomIdx()) for b in mol.GetBonds()])\n",
    "\n",
    "    try:\n",
    "        descriptors['graph_diameter'] = nx.diameter(g) if nx.is_connected(g) else 0\n",
    "        descriptors['avg_shortest_path'] = nx.average_shortest_path_length(g) if nx.is_connected(g) else 0\n",
    "    except:\n",
    "        descriptors['graph_diameter'] = 0\n",
    "        descriptors['avg_shortest_path'] = 0\n",
    "\n",
    "    descriptors['num_cycles'] = len(nx.cycle_basis(g))\n",
    "\n",
    "    try:\n",
    "        descriptors['betweenness_mean'] = np.mean(list(nx.betweenness_centrality(g).values()))\n",
    "        descriptors['betweenness_std'] = np.std(list(nx.betweenness_centrality(g).values()))\n",
    "        descriptors['closeness_mean'] = np.mean(list(nx.closeness_centrality(g).values()))\n",
    "        descriptors['max_degree'] = max(dict(g.degree()).values())\n",
    "    except:\n",
    "        descriptors['betweenness_mean'] = np.nan\n",
    "        descriptors['betweenness_std'] = np.nan\n",
    "        descriptors['closeness_mean'] = np.nan\n",
    "        descriptors['max_degree'] = np.nan\n",
    "\n",
    "    try:\n",
    "        ec = nx.eigenvector_centrality_numpy(g)\n",
    "        descriptors['eigenvector_mean'] = np.mean(list(ec.values()))\n",
    "    except:\n",
    "        descriptors['eigenvector_mean'] = np.nan\n",
    "\n",
    "    try:\n",
    "        katz = nx.katz_centrality_numpy(g)\n",
    "        descriptors['katz_centrality_std'] = np.std(list(katz.values()))\n",
    "    except:\n",
    "        descriptors['katz_centrality_std'] = np.nan\n",
    "\n",
    "    try:\n",
    "        ring_info = mol.GetRingInfo().AtomRings()\n",
    "        descriptors['ring_4'] = sum(1 for r in ring_info if len(r) == 4)\n",
    "    except:\n",
    "        descriptors['ring_4'] = 0\n",
    "\n",
    "    try:\n",
    "        descriptors['heteroatom_ratio'] = sum(1 for a in mol.GetAtoms() if a.GetAtomicNum() not in [1, 6]) / mol.GetNumAtoms()\n",
    "    except:\n",
    "        descriptors['heteroatom_ratio'] = np.nan\n",
    "\n",
    "    return descriptors\n",
    "\n",
    "# === Final Combined Feature Computation ===\n",
    "def compute_all_features(smiles_list, verbose=True):\n",
    "    smiles_list = canonicalize_smiles(smiles_list)\n",
    "\n",
    "    feature_dict = {}\n",
    "    valid_idx = []\n",
    "    failed_idx = []\n",
    "\n",
    "    for idx, smi in enumerate(tqdm(smiles_list, desc=\"Computing Features\")):\n",
    "        if smi is None:\n",
    "            failed_idx.append(idx)\n",
    "            continue\n",
    "\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        if mol is None:\n",
    "            failed_idx.append(idx)\n",
    "            continue\n",
    "\n",
    "        valid_idx.append(idx)\n",
    "        feats = {}\n",
    "        feats.update(compute_rdkit_descriptors(mol))\n",
    "        feats.update(compute_graph_descriptors(mol))\n",
    "\n",
    "        for k, v in feats.items():\n",
    "            if k not in feature_dict:\n",
    "                feature_dict[k] = []\n",
    "            feature_dict[k].append(v)\n",
    "\n",
    "    total = len(smiles_list)\n",
    "    for k in feature_dict:\n",
    "        if len(feature_dict[k]) < total:\n",
    "            feature_dict[k].extend([None] * (total - len(feature_dict[k])))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n--- Feature Engineering Summary ---\")\n",
    "        print(f\"Total SMILES: {total}\")\n",
    "        print(f\"Valid molecules: {len(valid_idx)}\")\n",
    "        print(f\"Invalid molecules: {len(failed_idx)}\")\n",
    "        print(f\"Number of computed features: {len(feature_dict)}\")\n",
    "        sample_key = next(iter(feature_dict))\n",
    "        print(f\"Feature vector length per molecule: {len(feature_dict[sample_key])}\")\n",
    "        print(\"-----------------------------------\")\n",
    "\n",
    "    return feature_dict, valid_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97f0d0f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T09:32:56.015778Z",
     "iopub.status.busy": "2025-07-30T09:32:56.015271Z",
     "iopub.status.idle": "2025-07-30T09:38:17.603736Z",
     "shell.execute_reply": "2025-07-30T09:38:17.602763Z"
    },
    "papermill": {
     "duration": 321.595382,
     "end_time": "2025-07-30T09:38:17.605209",
     "exception": false,
     "start_time": "2025-07-30T09:32:56.009827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8972/8972 [05:15<00:00, 28.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Engineering Summary ---\n",
      "Total SMILES: 8972\n",
      "Valid molecules: 8972\n",
      "Invalid molecules: 0\n",
      "Number of computed features: 228\n",
      "Feature vector length per molecule: 8972\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 23.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Engineering Summary ---\n",
      "Total SMILES: 3\n",
      "Valid molecules: 3\n",
      "Invalid molecules: 0\n",
      "Number of computed features: 228\n",
      "Feature vector length per molecule: 3\n",
      "-----------------------------------\n",
      "Train features shape: (8972, 159)\n",
      "Test features shape: (3, 159)\n",
      "Training dataframe Shape: (8972, 6)\n",
      "Test dataframe Shape: (3, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from rdkit import RDLogger\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress RDKit warnings\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "# List of columns to drop ,Source: from various Notebooks through out the competition\n",
    "useless_cols = [   \n",
    "    'MaxPartialCharge', \n",
    "    'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO',\n",
    "    'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW',\n",
    "    'NumRadicalElectrons', 'SMR_VSA8', 'SlogP_VSA9', 'fr_barbitur',\n",
    "    'fr_benzodiazepine', 'fr_dihydropyridine', 'fr_epoxide', 'fr_isothiocyan',\n",
    "    'fr_lactam', 'fr_nitroso', 'fr_prisulfonamd', 'fr_thiocyan',\n",
    "    'MaxEStateIndex', 'HeavyAtomMolWt', 'ExactMolWt', 'NumValenceElectrons',\n",
    "    'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Kappa1',\n",
    "    'LabuteASA', 'HeavyAtomCount', 'MolMR', 'Chi3n', 'BertzCT', 'Chi2v',\n",
    "    'Chi4n', 'HallKierAlpha', 'Chi3v', 'Chi4v', 'MinAbsPartialCharge',\n",
    "    'MinPartialCharge', 'MaxAbsPartialCharge', 'FpDensityMorgan2',\n",
    "    'FpDensityMorgan3', 'Phi', 'Kappa3', 'fr_nitrile', 'SlogP_VSA6',\n",
    "    'NumAromaticCarbocycles', 'NumAromaticRings', 'fr_benzene', 'VSA_EState6',\n",
    "    'NOCount', 'fr_C_O', 'fr_C_O_noCOO', 'NumHDonors', 'fr_amide',\n",
    "    'fr_Nhpyrrole', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_COO2',\n",
    "    'fr_halogen', 'fr_diazo', 'fr_nitro_arom', 'fr_phos_ester'\n",
    "]\n",
    "\n",
    "# === Compute Train Features ===\n",
    "feature_dict_train, valid_idx_train = compute_all_features(train_extended[\"SMILES\"], verbose=True)\n",
    "features_train = pd.DataFrame(feature_dict_train).reset_index(drop=True)\n",
    "features_train = features_train.drop(columns=[col for col in useless_cols if col in features_train.columns])\n",
    "\n",
    "# === Compute Test Features ===\n",
    "feature_dict_test, valid_idx_test = compute_all_features(test[\"SMILES\"], verbose=True)\n",
    "features_test = pd.DataFrame(feature_dict_test).reset_index(drop=True)\n",
    "features_test = features_test.drop(columns=[col for col in useless_cols if col in features_test.columns])\n",
    "\n",
    "# === Output Summary ===\n",
    "print(\"Train features shape:\", features_train.shape)\n",
    "print(\"Test features shape:\", features_test.shape)\n",
    "print(\"Training dataframe Shape:\", train_extended.shape)\n",
    "print(\"Test dataframe Shape:\", test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c972bea",
   "metadata": {
    "papermill": {
     "duration": 0.108646,
     "end_time": "2025-07-30T09:38:17.824524",
     "exception": false,
     "start_time": "2025-07-30T09:38:17.715878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prerprocessing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab42714d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T09:38:18.047807Z",
     "iopub.status.busy": "2025-07-30T09:38:18.046791Z",
     "iopub.status.idle": "2025-07-30T09:38:19.662647Z",
     "shell.execute_reply": "2025-07-30T09:38:19.661537Z"
    },
    "papermill": {
     "duration": 1.729325,
     "end_time": "2025-07-30T09:38:19.664445",
     "exception": false,
     "start_time": "2025-07-30T09:38:17.935120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Preprocessing Train features\n",
      "  - Replacing 0 ¬±inf values with NaN...\n",
      "  - Dropping 0 all-NaN columns...\n",
      "  - Filling 0 remaining NaNs with column means...\n",
      "\n",
      "üì¶ Preprocessing Test features\n",
      "  - Replacing 0 ¬±inf values with NaN...\n",
      "  - Dropping 0 all-NaN columns...\n",
      "  - Filling 0 remaining NaNs with column means...\n",
      "\n",
      "üßπ Applying VarianceThreshold (threshold=1e-05)...\n",
      "  - Removed 0 low-variance features.\n",
      "\n",
      "üßØ Clipping outliers to range [-1000000.0, 1000000.0]...\n",
      "  - Clipping 1 overly large and 0 overly small features.\n",
      "\n",
      "üßØ Clipping outliers to range [-1000000.0, 1000000.0]...\n",
      "  - Clipping 1 overly large and 0 overly small features.\n",
      "\n",
      "‚úÖ Final Preprocessing Summary:\n",
      "  - Train shape: (8972, 159)\n",
      "  - Test shape:  (3, 159)\n",
      "  - Common features retained: 159\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# === Preprocessing Utilities ===\n",
    "\n",
    "def preprocess_features(df, df_name=\"\"):\n",
    "    print(f\"\\nüì¶ Preprocessing {df_name} features\")\n",
    "\n",
    "    # 1. Replace inf/-inf with NaN\n",
    "    inf_count = np.isinf(df.values).sum()\n",
    "    print(f\"  - Replacing {inf_count} ¬±inf values with NaN...\")\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # 2. Drop columns that are entirely NaN\n",
    "    all_nan_cols = df.columns[df.isna().all()].tolist()\n",
    "    print(f\"  - Dropping {len(all_nan_cols)} all-NaN columns...\")\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # 3. Fill remaining NaNs with column means\n",
    "    nan_count = df.isna().sum().sum()\n",
    "    print(f\"  - Filling {nan_count} remaining NaNs with column means...\")\n",
    "    df = df.fillna(df.mean())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def detect_outliers(df, threshold=1e10):\n",
    "    max_vals = df.max()\n",
    "    min_vals = df.min()\n",
    "    too_large = max_vals[max_vals > threshold]\n",
    "    too_small = min_vals[min_vals < -threshold]\n",
    "    return too_large, too_small\n",
    "\n",
    "\n",
    "def remove_low_variance(df, threshold=1e-5):\n",
    "    print(f\"\\nüßπ Applying VarianceThreshold (threshold={threshold})...\")\n",
    "    selector = VarianceThreshold(threshold=threshold)\n",
    "    reduced = selector.fit_transform(df)\n",
    "    kept_cols = df.columns[selector.get_support()]\n",
    "    removed_count = df.shape[1] - len(kept_cols)\n",
    "    print(f\"  - Removed {removed_count} low-variance features.\")\n",
    "    return pd.DataFrame(reduced, columns=kept_cols)\n",
    "\n",
    "\n",
    "def clip_outliers(df, lower=-1e6, upper=1e6):\n",
    "    print(f\"\\nüßØ Clipping outliers to range [{lower}, {upper}]...\")\n",
    "    too_large, too_small = detect_outliers(df)\n",
    "    if not too_large.empty or not too_small.empty:\n",
    "        print(f\"  - Clipping {len(too_large)} overly large and {len(too_small)} overly small features.\")\n",
    "        df = df.clip(lower, upper)\n",
    "    else:\n",
    "        print(\"  - No extreme outliers found.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# === Apply Preprocessing ===\n",
    "\n",
    "# Make sure your features_train and features_test already exist\n",
    "features_train_clean = preprocess_features(features_train, df_name=\"Train\")\n",
    "features_test_clean = preprocess_features(features_test, df_name=\"Test\")\n",
    "\n",
    "# Align both datasets\n",
    "common_cols = features_train_clean.columns.intersection(features_test_clean.columns)\n",
    "features_train_clean = features_train_clean[common_cols].copy()\n",
    "features_test_clean = features_test_clean[common_cols].copy()\n",
    "\n",
    "# Remove near-zero variance features\n",
    "features_train_clean = remove_low_variance(features_train_clean)\n",
    "features_test_clean = features_test_clean[features_train_clean.columns]  # Align\n",
    "\n",
    "# Clip extreme outliers\n",
    "features_train_clean = clip_outliers(features_train_clean)\n",
    "features_test_clean = clip_outliers(features_test_clean)\n",
    "\n",
    "# === Summary ===\n",
    "print(\"\\n‚úÖ Final Preprocessing Summary:\")\n",
    "print(f\"  - Train shape: {features_train_clean.shape}\")\n",
    "print(f\"  - Test shape:  {features_test_clean.shape}\")\n",
    "print(f\"  - Common features retained: {len(features_train_clean.columns)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9eab04",
   "metadata": {
    "papermill": {
     "duration": 0.110581,
     "end_time": "2025-07-30T09:38:19.887981",
     "exception": false,
     "start_time": "2025-07-30T09:38:19.777400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ExtraTrees Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83de0fa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T09:38:20.109277Z",
     "iopub.status.busy": "2025-07-30T09:38:20.108787Z",
     "iopub.status.idle": "2025-07-30T09:38:44.597937Z",
     "shell.execute_reply": "2025-07-30T09:38:44.596863Z"
    },
    "papermill": {
     "duration": 24.601045,
     "end_time": "2025-07-30T09:38:44.599716",
     "exception": false,
     "start_time": "2025-07-30T09:38:19.998671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Training ExtraTrees for target: Tg\n",
      "  üß™ Fold 1/5\n",
      "     üîç Fold MAE: 57.25228\n",
      "  üß™ Fold 2/5\n",
      "     üîç Fold MAE: 56.72785\n",
      "  üß™ Fold 3/5\n",
      "     üîç Fold MAE: 51.50944\n",
      "  üß™ Fold 4/5\n",
      "     üîç Fold MAE: 45.37280\n",
      "  üß™ Fold 5/5\n",
      "     üîç Fold MAE: 53.54996\n",
      "\n",
      "üéØ Training ExtraTrees for target: FFV\n",
      "  üß™ Fold 1/5\n",
      "     üîç Fold MAE: 0.00656\n",
      "  üß™ Fold 2/5\n",
      "     üîç Fold MAE: 0.00629\n",
      "  üß™ Fold 3/5\n",
      "     üîç Fold MAE: 0.00627\n",
      "  üß™ Fold 4/5\n",
      "     üîç Fold MAE: 0.00653\n",
      "  üß™ Fold 5/5\n",
      "     üîç Fold MAE: 0.00685\n",
      "\n",
      "üéØ Training ExtraTrees for target: Tc\n",
      "  üß™ Fold 1/5\n",
      "     üîç Fold MAE: 0.02888\n",
      "  üß™ Fold 2/5\n",
      "     üîç Fold MAE: 0.02835\n",
      "  üß™ Fold 3/5\n",
      "     üîç Fold MAE: 0.03994\n",
      "  üß™ Fold 4/5\n",
      "     üîç Fold MAE: 0.02966\n",
      "  üß™ Fold 5/5\n",
      "     üîç Fold MAE: 0.03736\n",
      "\n",
      "üéØ Training ExtraTrees for target: Density\n",
      "  üß™ Fold 1/5\n",
      "     üîç Fold MAE: 0.03314\n",
      "  üß™ Fold 2/5\n",
      "     üîç Fold MAE: 0.05058\n",
      "  üß™ Fold 3/5\n",
      "     üîç Fold MAE: 0.02847\n",
      "  üß™ Fold 4/5\n",
      "     üîç Fold MAE: 0.02528\n",
      "  üß™ Fold 5/5\n",
      "     üîç Fold MAE: 0.03345\n",
      "\n",
      "üéØ Training ExtraTrees for target: Rg\n",
      "  üß™ Fold 1/5\n",
      "     üîç Fold MAE: 2.01267\n",
      "  üß™ Fold 2/5\n",
      "     üîç Fold MAE: 1.95949\n",
      "  üß™ Fold 3/5\n",
      "     üîç Fold MAE: 1.86481\n",
      "  üß™ Fold 4/5\n",
      "     üîç Fold MAE: 1.62189\n",
      "  üß™ Fold 5/5\n",
      "     üîç Fold MAE: 1.65994\n",
      "\n",
      "‚úÖ All models trained.\n",
      "üìÅ Submission saved as submission.csv\n",
      "\n",
      "üìä Final Evaluation ‚Äî Weighted MAE (wMAE):\n",
      "‚úÖ wMAE: 0.107034\n",
      "   ‚Ä¢ Tg: weight = 0.000842\n",
      "   ‚Ä¢ FFV: weight = 0.252186\n",
      "   ‚Ä¢ Tc: weight = 0.271328\n",
      "   ‚Ä¢ Density: weight = 0.455706\n",
      "   ‚Ä¢ Rg: weight = 0.019939\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# === Configuration ===\n",
    "target_cols = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "n_splits = 5\n",
    "random_seed = 42\n",
    "\n",
    "# === wMAE Computation (aligned with competition metric) ===\n",
    "def compute_wmae(oof_df, true_df, target_cols):\n",
    "    \"\"\"\n",
    "    Compute weighted MAE (wMAE) using reweighting formula from competition rules.\n",
    "    \"\"\"\n",
    "    ranges = {}\n",
    "    avail_counts = {}\n",
    "\n",
    "    for col in target_cols:\n",
    "        mask = ~true_df[col].isna()\n",
    "        y_true = true_df.loc[mask, col]\n",
    "        ranges[col] = y_true.max() - y_true.min()\n",
    "        avail_counts[col] = mask.sum()\n",
    "\n",
    "    # Inverse sqrt of availability and scaled by inverse of value range\n",
    "    unnormalized_weights = {\n",
    "        col: (1 / np.sqrt(avail_counts[col])) / ranges[col]\n",
    "        for col in target_cols\n",
    "    }\n",
    "\n",
    "    total_weight = sum(unnormalized_weights.values())\n",
    "    weights = {col: w / total_weight for col, w in unnormalized_weights.items()}\n",
    "\n",
    "    # Compute weighted MAE\n",
    "    wmae = 0\n",
    "    for col in target_cols:\n",
    "        mask = ~true_df[col].isna()\n",
    "        error = np.abs(oof_df.loc[mask, col] - true_df.loc[mask, col])\n",
    "        wmae += weights[col] * error.mean()\n",
    "\n",
    "    return wmae, weights\n",
    "\n",
    "# === Cross-validation Training ===\n",
    "test_preds = pd.DataFrame(index=features_test_clean.index)\n",
    "oof_preds = pd.DataFrame(index=features_train_clean.index)\n",
    "\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "\n",
    "for target in target_cols:\n",
    "    print(f\"\\nüéØ Training ExtraTrees for target: {target}\")\n",
    "\n",
    "    mask = ~train_extended[target].isna()\n",
    "    X = features_train_clean.loc[mask]\n",
    "    y = train_extended.loc[mask, target]\n",
    "\n",
    "    oof_pred = np.zeros(X.shape[0])\n",
    "    test_fold_preds = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"  üß™ Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = ExtraTreesRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features='sqrt',\n",
    "            bootstrap=False,\n",
    "            random_state=random_seed,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        val_pred = model.predict(X_val)\n",
    "        test_pred = model.predict(features_test_clean)\n",
    "\n",
    "        oof_pred[val_idx] = val_pred\n",
    "        test_fold_preds.append(test_pred)\n",
    "\n",
    "        fold_mae = mean_absolute_error(y_val, val_pred)\n",
    "        print(f\"     üîç Fold MAE: {fold_mae:.5f}\")\n",
    "\n",
    "    oof_preds.loc[mask, target] = oof_pred\n",
    "    test_preds[target] = np.mean(test_fold_preds, axis=0)\n",
    "\n",
    "print(\"\\n‚úÖ All models trained.\")\n",
    "\n",
    "# === Submission ===\n",
    "submission = test[['id']].copy()\n",
    "submission = pd.concat([submission, test_preds], axis=1)\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"üìÅ Submission saved as submission.csv\")\n",
    "\n",
    "# === Evaluation ===\n",
    "wmae_score, weight_map = compute_wmae(oof_preds, train_extended, target_cols)\n",
    "\n",
    "print(\"\\nüìä Final Evaluation ‚Äî Weighted MAE (wMAE):\")\n",
    "print(f\"‚úÖ wMAE: {wmae_score:.6f}\")\n",
    "for t in target_cols:\n",
    "    print(f\"   ‚Ä¢ {t}: weight = {weight_map[t]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de1643f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-30T09:38:44.829660Z",
     "iopub.status.busy": "2025-07-30T09:38:44.828740Z",
     "iopub.status.idle": "2025-07-30T09:38:44.839809Z",
     "shell.execute_reply": "2025-07-30T09:38:44.838954Z"
    },
    "papermill": {
     "duration": 0.129216,
     "end_time": "2025-07-30T09:38:44.841214",
     "exception": false,
     "start_time": "2025-07-30T09:38:44.711998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Tg</th>\n",
       "      <th>FFV</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Density</th>\n",
       "      <th>Rg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1109053969</td>\n",
       "      <td>154.772320</td>\n",
       "      <td>0.373127</td>\n",
       "      <td>0.202526</td>\n",
       "      <td>1.147388</td>\n",
       "      <td>20.096992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1422188626</td>\n",
       "      <td>149.139589</td>\n",
       "      <td>0.374912</td>\n",
       "      <td>0.238176</td>\n",
       "      <td>1.094483</td>\n",
       "      <td>19.666001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2032016830</td>\n",
       "      <td>105.683468</td>\n",
       "      <td>0.350509</td>\n",
       "      <td>0.257660</td>\n",
       "      <td>1.118860</td>\n",
       "      <td>19.975709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id          Tg       FFV        Tc   Density         Rg\n",
       "0  1109053969  154.772320  0.373127  0.202526  1.147388  20.096992\n",
       "1  1422188626  149.139589  0.374912  0.238176  1.094483  19.666001\n",
       "2  2032016830  105.683468  0.350509  0.257660  1.118860  19.975709"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12966160,
     "sourceId": 74608,
     "sourceType": "competition"
    },
    {
     "datasetId": 7678100,
     "sourceId": 12189904,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 376.832553,
   "end_time": "2025-07-30T09:38:45.875796",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-30T09:32:29.043243",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
